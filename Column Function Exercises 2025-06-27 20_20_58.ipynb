{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e215d7c-5f07-4322-801e-50c58f756fcb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-------+------+\n| name| age|country|salary|\n+-----+----+-------+------+\n|Priya|  25|  India|  4000|\n|Aryan|  30|   NULL|  5000|\n|Kavya|  28|    USA|  6000|\n|  Ram|NULL|     UK|  4500|\n+-----+----+-------+------+\n\nroot\n |-- name: string (nullable = true)\n |-- age: string (nullable = true)\n |-- country: string (nullable = true)\n |-- salary: long (nullable = true)\n\n+---------+-------+-----------+------+-------------+--------------+\n|full_name|age_int|has_country|has_ya|starts_with_P|updated_salary|\n+---------+-------+-----------+------+-------------+--------------+\n|    Priya|     25|       true|  true|         true|          5000|\n|    Aryan|     30|      false|  true|        false|          6000|\n|    Kavya|     28|       true|  true|        false|          7000|\n|      Ram|   NULL|       true| false|        false|          5500|\n+---------+-------+-----------+------+-------------+--------------+\n\nroot\n |-- full_name: string (nullable = true)\n |-- age_int: integer (nullable = true)\n |-- has_country: boolean (nullable = false)\n |-- has_ya: boolean (nullable = true)\n |-- starts_with_P: boolean (nullable = true)\n |-- updated_salary: long (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Step 1: Create SparkSession\n",
    "spark = SparkSession.builder.appName(\"ColumnFunctionsExample\").getOrCreate()\n",
    "\n",
    "# Step 2: Sample DataFrame\n",
    "data = [\n",
    "    (\"Priya\", \"25\", \"India\", 4000),\n",
    "    (\"Aryan\", \"30\", None, 5000),\n",
    "    (\"Kavya\", \"28\", \"USA\", 6000),\n",
    "    (\"Ram\", None, \"UK\", 4500)\n",
    "]\n",
    "df = spark.createDataFrame(data, [\"name\", \"age\", \"country\", \"salary\"])\n",
    "\n",
    "# Step 3: Use column functions\n",
    "df_transformed = df.select(\n",
    "    col(\"name\").alias(\"full_name\"),                  # rename column\n",
    "    col(\"age\").cast(\"int\").alias(\"age_int\"),         # convert age from string to int\n",
    "    col(\"country\").isNotNull().alias(\"has_country\"), # check for nulls\n",
    "    col(\"name\").contains(\"ya\").alias(\"has_ya\"),      # contains \"ya\" in name\n",
    "    col(\"name\").startswith(\"P\").alias(\"starts_with_P\"), # name starts with P\n",
    "    (col(\"salary\") + 1000).alias(\"updated_salary\")   # add 1000 to salary\n",
    ")\n",
    "\n",
    "# Step 4: Show results\n",
    "df.show()\n",
    "df.printSchema()\n",
    "df_transformed.show()\n",
    "df_transformed.printSchema()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Column Function Exercises 2025-06-27 20:20:58",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}