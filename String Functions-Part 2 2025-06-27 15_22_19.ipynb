{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1e98359-ade3-42de-be4a-c598b8d30bcf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-------+-----+-----+\n|firstname|  lastname|country|state|  sal|\n+---------+----------+-------+-----+-----+\n|     raja|pushpa    |    USA|     |30000|\n|    priya|    pushpa|    USA|     |29900|\n|  Karthik|      Subu|    USA|   CA| Null|\n|    James|     Smith|    USA|   FL|20000|\n|   Martin|     Jones|    USA|   CA| 3000|\n|      Sam|  Anderson|     UK|  LND| 8000|\n|    Maria|   Patrick|     UK|  MCR| 7000|\n|    Robet|     Bevon|     UK|  LND| 3500|\n|    Maria|  Anderson|     UK|  MCR| 3000|\n+---------+----------+-------+-----+-----+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "staticlist = [(\" raja\", \"pushpa    \", \"USA\",\"\",30000),\n",
    "            (\" priya\", \"pushpa\", \"USA\",\"\",29900),\n",
    "            (\" Karthik\", \"Subu\", \"USA\",\"CA\",\"Null\"),\n",
    "            (\" James\", \"Smith\", \"USA\",\"FL\",20000),\n",
    "            (\"Martin\", \"Jones\", \"USA\",\"CA\",3000),\n",
    "            (\"Sam\", \"Anderson\", \"UK\",\"LND\",8000),\n",
    "            (\"Maria\", \"Patrick\", \"UK\",\"MCR\",7000),\n",
    "            (\"Robet\", \"Bevon\", \"UK\",\"LND\",3500),\n",
    "            (\"Maria\", \"Anderson\", \"UK\",\"MCR\",3000)\n",
    "            ]\n",
    "columns = [\"firstname\",\"lastname\",\"country\",\"state\",\"sal\"]            \n",
    "df = spark.createDataFrame( data = staticlist, schema = columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df2d05a8-e866-46b2-a4e5-e4891e2f4c13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Expression language : whenever a pyspark funcation is not found, we can use SQL statement inside a pyspark stetement using the expression language\n",
    "#syntax: expr(\"SQL STATEMENT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25cdccd7-3b76-4560-85de-dc08a524ce50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-------+-----+-----+---------------+\n|firstname|  lastname|country|state|  sal|Updated_Country|\n+---------+----------+-------+-----+-----+---------------+\n|     raja|pushpa    |    USA|     |30000|  UNITED STATES|\n|    priya|    pushpa|    USA|     |29900|  UNITED STATES|\n|  Karthik|      Subu|    USA|   CA| Null|  UNITED STATES|\n|    James|     Smith|    USA|   FL|20000|  UNITED STATES|\n|   Martin|     Jones|    USA|   CA| 3000|  UNITED STATES|\n|      Sam|  Anderson|     UK|  LND| 8000|             UK|\n|    Maria|   Patrick|     UK|  MCR| 7000|             UK|\n|    Robet|     Bevon|     UK|  LND| 3500|             UK|\n|    Maria|  Anderson|     UK|  MCR| 3000|             UK|\n+---------+----------+-------+-----+-----+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "# REPLACE USA WITH UNITTED STATES\n",
    "from pyspark.sql.functions import *\n",
    "df_replace_expr = df.withColumn(\"Updated_Country\",expr(\"case when country = 'USA' then 'UNITED STATES' else country end\"))\n",
    "df_replace_expr.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe98a829-4ea5-4c39-bdc4-68fa319fcc41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-------+-----+-----+---------------+\n|firstname|  lastname|country|state|  sal|Updated_Country|\n+---------+----------+-------+-----+-----+---------------+\n|     raja|pushpa    |    USA|     |30000|  UNITED STATES|\n|    priya|    pushpa|    USA|     |29900|  UNITED STATES|\n|  Karthik|      Subu|    USA|   CA| Null|  UNITED STATES|\n|    James|     Smith|    USA|   FL|20000|  UNITED STATES|\n|   Martin|     Jones|    USA|   CA| 3000|  UNITED STATES|\n|      Sam|  Anderson|     UK|  LND| 8000|             UK|\n|    Maria|   Patrick|     UK|  MCR| 7000|             UK|\n|    Robet|     Bevon|     UK|  LND| 3500|             UK|\n|    Maria|  Anderson|     UK|  MCR| 3000|             UK|\n+---------+----------+-------+-----+-----+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "df_replace_direct = df.withColumn(\"Updated_Country\", expr(\"replace(country,'USA','UNITED STATES')\"))\n",
    "df_replace_direct.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "415afdbe-5fb5-4fb4-8fe9-6581d30dba91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------------+-----+-----+\n|firstname|  lastname|       country|state|  sal|\n+---------+----------+--------------+-----+-----+\n|     raja|pushpa    |           USA|     |30000|\n|    priya|    pushpa|           USA|     |29900|\n|  Karthik|      Subu|           USA|   CA| Null|\n|    James|     Smith|           USA|   FL|20000|\n|   Martin|     Jones|           USA|   CA| 3000|\n|      Sam|  Anderson|United Kingdom|  LND| 8000|\n|    Maria|   Patrick|United Kingdom|  MCR| 7000|\n|    Robet|     Bevon|United Kingdom|  LND| 3500|\n|    Maria|  Anderson|United Kingdom|  MCR| 3000|\n+---------+----------+--------------+-----+-----+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.column import *\n",
    "#df_replace=df.withColumn(\"Country_Updated\", col(\"country\").replace(\"UK\", \"United Kingdom\"))\n",
    "df_replace = df.replace(\"UK\", \"United Kingdom\", subset=[\"country\"])\n",
    "df_replace.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "String Functions-Part 2 2025-06-27 15:22:19",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}